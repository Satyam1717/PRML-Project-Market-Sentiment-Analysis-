{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b458a9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# Install required packages\n",
    "!pip install gensim\n",
    "!pip install --upgrade numpy\n",
    "\n",
    "# Load your preprocessed CSV file\n",
    "df = pd.read_csv('labelled_news_sentiment.csv')\n",
    "\n",
    "# Tokenize the processed text\n",
    "df['tokens'] = df['processed_text'].apply(lambda x: x.split())\n",
    "\n",
    "print(\"Sample tokens:\", df['tokens'].head())\n",
    "\n",
    "# Prepare documents for Doc2Vec - each document needs to be tagged with an index\n",
    "tagged_data = [TaggedDocument(words=tokens, tags=[str(i)]) for i, tokens in enumerate(df['tokens'])]\n",
    "\n",
    "# Train the Doc2Vec model\n",
    "d2v_model = Doc2Vec(vector_size=100,    # Dimension of the document vectors\n",
    "                    window=5,           # Context window size\n",
    "                    min_count=1,         # Minimum frequency for a word to be considered\n",
    "                    workers=10,          # Number of threads for training\n",
    "                    epochs=30,           # Number of training epochs\n",
    "                    dm=1)                # Training algorithm: 1 = distributed memory (PV-DM); 0 = distributed bag of words (PV-DBOW)\n",
    "\n",
    "# Build vocabulary\n",
    "d2v_model.build_vocab(tagged_data)\n",
    "\n",
    "# Train the model\n",
    "d2v_model.train(tagged_data, total_examples=d2v_model.corpus_count, epochs=d2v_model.epochs)\n",
    "\n",
    "print(\"Doc2Vec model trained.\")\n",
    "\n",
    "# Generate document vectors using the trained model\n",
    "doc_vectors = np.array([d2v_model.dv[str(i)] for i in range(len(df))])\n",
    "\n",
    "print(\"Document vectors shape:\", doc_vectors.shape)\n",
    "\n",
    "# Set up features and target\n",
    "X = doc_vectors\n",
    "y = df['news_sentiment'].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
