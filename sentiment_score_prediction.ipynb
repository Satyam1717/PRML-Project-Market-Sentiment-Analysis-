{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import xgboost as xgb\n",
    "from collections import Counter\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "# Load the new dataset\n",
    "new_df = pd.read_csv('preprocessed_news_data.csv')\n",
    "\n",
    "# Ensure the 'processed_text' column exists\n",
    "if 'processed_text' not in new_df.columns:\n",
    "    raise ValueError(\"The input CSV must contain a 'processed_text' column.\")\n",
    "\n",
    "# Tokenize the processed text\n",
    "new_df['tokens'] = new_df['processed_text'].apply(lambda x: x.split())\n",
    "\n",
    "# Load the trained Word2Vec model\n",
    "w2v_model = Word2Vec.load(\"word2vec_model.model\")\n",
    "\n",
    "# Calculate IDF values using only the new dataset\n",
    "def calculate_idf(corpus):\n",
    "    total_documents = len(corpus)\n",
    "    word_document_count = Counter()\n",
    "    for document in corpus:\n",
    "        unique_words = set(document)\n",
    "        for word in unique_words:\n",
    "            word_document_count[word] += 1\n",
    "    idf_values = {word: math.log(total_documents / (1 + count)) for word, count in word_document_count.items()}\n",
    "    return idf_values\n",
    "\n",
    "# Use the new dataset to calculate IDF values\n",
    "new_corpus = new_df['tokens'].tolist()\n",
    "idf_values = calculate_idf(new_corpus)\n",
    "\n",
    "# Define function to calculate TF-IDF weighted document vectors\n",
    "def calculate_tfidf_weighted_doc_vector(tokens, idf_values, w2v_model):\n",
    "    tf_values = Counter(tokens)\n",
    "    total_terms = len(tokens)\n",
    "    tf_values = {word: count / total_terms for word, count in tf_values.items()}\n",
    "    weighted_sum = np.zeros(w2v_model.vector_size)\n",
    "    total_weight = 0.0\n",
    "    for token in tokens:\n",
    "        if token in w2v_model.wv and token in idf_values:\n",
    "            tfidf_score = tf_values[token] * idf_values[token]\n",
    "            weighted_sum += w2v_model.wv[token] * tfidf_score\n",
    "            total_weight += tfidf_score\n",
    "    if total_weight > 0:\n",
    "        return weighted_sum / total_weight\n",
    "    else:\n",
    "        return np.zeros(w2v_model.vector_size)\n",
    "\n",
    "# Generate document vectors for the new dataset\n",
    "new_doc_vectors = []\n",
    "for tokens in new_df['tokens']:\n",
    "    doc_vector = calculate_tfidf_weighted_doc_vector(tokens, idf_values, w2v_model)\n",
    "    new_doc_vectors.append(doc_vector)\n",
    "\n",
    "new_doc_vectors = np.array(new_doc_vectors)\n",
    "\n",
    "# Load the trained XGBoost model from pickle file\n",
    "with open('xgboost_model.pkl', 'rb') as f:\n",
    "    xgb_model = pickle.load(f)\n",
    "\n",
    "# Convert document vectors to DMatrix format for prediction\n",
    "dnew = xgb.DMatrix(new_doc_vectors)\n",
    "\n",
    "# Predict sentiment scores using the trained XGBoost model\n",
    "new_df['sentiment_score'] = xgb_model.predict(dnew)\n",
    "\n",
    "# Save the updated DataFrame with sentiment scores to a new CSV file\n",
    "new_df.to_csv('new_articles_with_sentiment.csv', index=False)\n",
    "\n",
    "print(\"Sentiment scores have been added and saved to 'new_articles_with_sentiment.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset with sentiment scores\n",
    "df = pd.read_csv('new_articles_with_sentiment.csv')\n",
    "\n",
    "# Calculate EWMA with different span values (adjust these as needed)\n",
    "spans = [3,5, 10,15]  # Different window sizes for comparison\n",
    "\n",
    "# Create new columns for each EWMA calculation\n",
    "for span in spans:\n",
    "    column_name = f'ewma_{span}'\n",
    "    df[column_name] = df['sentiment_score'].ewm(span=span).mean()\n",
    "\n",
    "# Save the updated DataFrame with EWMA columns\n",
    "df.to_csv('new_articles_with_ewma.csv', index=False)\n",
    "print(f\"EWMA calculations added to the dataset and saved to 'new_articles_with_ewma.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the original sentiment scores\n",
    "plt.plot(df.index, df['sentiment_score'], label='Raw Sentiment Score', color='gray', alpha=0.6)\n",
    "\n",
    "# Plot each EWMA line\n",
    "colors = ['blue', 'red', 'green']\n",
    "for span, color in zip(spans, colors):\n",
    "    column_name = f'ewma_{span}'\n",
    "    plt.plot(df.index, df[column_name], label=f'EWMA (span={span})', color=color, linewidth=2)\n",
    "\n",
    "# Add chart details\n",
    "plt.title('Sentiment Scores with EWMA Smoothing', fontsize=16)\n",
    "plt.xlabel('Article Index', fontsize=12)\n",
    "plt.ylabel('Sentiment Score', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Save the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('sentiment_ewma_comparison.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"Graph saved as 'sentiment_ewma_comparison.png'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
