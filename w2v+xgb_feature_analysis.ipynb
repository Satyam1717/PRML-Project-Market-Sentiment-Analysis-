{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tIEWOtlDvR7A",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIEWOtlDvR7A",
        "outputId": "5048a218-b299-43e7-e67d-db2a68df568f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Found existing installation: pandas 2.2.2\n",
            "Uninstalling pandas-2.2.2:\n",
            "  Successfully uninstalled pandas-2.2.2\n",
            "Found existing installation: thinc 8.2.5\n",
            "Uninstalling thinc-8.2.5:\n",
            "  Successfully uninstalled thinc-8.2.5\n",
            "Found existing installation: spacy 3.7.6\n",
            "Uninstalling spacy-3.7.6:\n",
            "  Successfully uninstalled spacy-3.7.6\n",
            "Found existing installation: gensim 4.3.3\n",
            "Uninstalling gensim-4.3.3:\n",
            "  Successfully uninstalled gensim-4.3.3\n",
            "Found existing installation: scipy 1.13.1\n",
            "Uninstalling scipy-1.13.1:\n",
            "  Successfully uninstalled scipy-1.13.1\n",
            "Collecting numpy==1.26.2\n",
            "  Using cached numpy-1.26.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "Installing collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scs 3.2.7.post2 requires scipy, which is not installed.\n",
            "jaxlib 0.5.1 requires scipy>=1.11.1, which is not installed.\n",
            "cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, which is not installed.\n",
            "pandas-gbq 0.28.0 requires pandas>=1.1.4, which is not installed.\n",
            "treelite 4.4.1 requires scipy, which is not installed.\n",
            "matplotlib-venn 1.1.2 requires scipy, which is not installed.\n",
            "mlxtend 0.23.4 requires pandas>=0.24.2, which is not installed.\n",
            "mlxtend 0.23.4 requires scipy>=1.2.1, which is not installed.\n",
            "pymc 5.21.2 requires pandas>=0.24.0, which is not installed.\n",
            "pymc 5.21.2 requires scipy>=1.4.1, which is not installed.\n",
            "bqplot 0.12.44 requires pandas<3.0.0,>=1.0.0, which is not installed.\n",
            "bigframes 1.42.0 requires pandas>=1.5.3, which is not installed.\n",
            "clarabel 0.10.0 requires scipy, which is not installed.\n",
            "osqp 1.0.3 requires scipy>=0.13.2, which is not installed.\n",
            "arviz 0.21.0 requires pandas>=1.5.0, which is not installed.\n",
            "arviz 0.21.0 requires scipy>=1.9.0, which is not installed.\n",
            "lightgbm 4.5.0 requires scipy, which is not installed.\n",
            "jax 0.5.2 requires scipy>=1.11.1, which is not installed.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, which is not installed.\n",
            "xarray-einstats 0.8.0 requires scipy>=1.9, which is not installed.\n",
            "cvxpy 1.6.4 requires scipy>=1.11.0, which is not installed.\n",
            "xgboost 2.1.4 requires scipy, which is not installed.\n",
            "yfinance 0.2.55 requires pandas>=1.3.0, which is not installed.\n",
            "hdbscan 0.8.40 requires scipy>=1.0, which is not installed.\n",
            "shap 0.47.1 requires pandas, which is not installed.\n",
            "shap 0.47.1 requires scipy, which is not installed.\n",
            "datascience 0.17.6 requires pandas, which is not installed.\n",
            "datascience 0.17.6 requires scipy, which is not installed.\n",
            "yellowbrick 1.5 requires scipy>=1.0.0, which is not installed.\n",
            "geemap 0.35.3 requires pandas, which is not installed.\n",
            "bokeh 3.6.3 requires pandas>=1.2, which is not installed.\n",
            "pytensor 2.30.2 requires scipy<2,>=1, which is not installed.\n",
            "imbalanced-learn 0.13.0 requires scipy<2,>=1.10.1, which is not installed.\n",
            "albumentations 2.0.5 requires scipy>=1.10.0, which is not installed.\n",
            "holoviews 1.20.2 requires pandas>=1.3, which is not installed.\n",
            "mizani 0.13.2 requires pandas>=2.2.0, which is not installed.\n",
            "mizani 0.13.2 requires scipy>=1.8.0, which is not installed.\n",
            "prophet 1.1.6 requires pandas>=1.0.4, which is not installed.\n",
            "panel 1.6.2 requires pandas>=1.2, which is not installed.\n",
            "cmdstanpy 1.2.5 requires pandas, which is not installed.\n",
            "statsmodels 0.14.4 requires pandas!=2.1.0,>=1.4, which is not installed.\n",
            "statsmodels 0.14.4 requires scipy!=1.9.2,>=1.8, which is not installed.\n",
            "seaborn 0.13.2 requires pandas>=1.2, which is not installed.\n",
            "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, which is not installed.\n",
            "dopamine-rl 4.1.2 requires pandas>=0.24.2, which is not installed.\n",
            "db-dtypes 1.4.2 requires pandas>=0.24.2, which is not installed.\n",
            "dask-cuda 25.2.0 requires pandas>=1.3, which is not installed.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, which is not installed.\n",
            "plotnine 0.14.5 requires scipy>=1.8.0, which is not installed.\n",
            "xarray 2025.1.2 requires pandas>=2.1, which is not installed.\n",
            "librosa 0.11.0 requires scipy>=1.6.0, which is not installed.\n",
            "sklearn-pandas 2.2.0 requires pandas>=1.1.4, which is not installed.\n",
            "sklearn-pandas 2.2.0 requires scipy>=1.5.1, which is not installed.\n",
            "fastai 2.7.19 requires pandas, which is not installed.\n",
            "fastai 2.7.19 requires scipy, which is not installed.\n",
            "fastai 2.7.19 requires spacy<4, which is not installed.\n",
            "scikit-learn 1.6.1 requires scipy>=1.6.0, which is not installed.\n",
            "missingno 0.5.2 requires scipy, which is not installed.\n",
            "cufflinks 0.17.3 requires pandas>=0.19.2, which is not installed.\n",
            "cuml-cu12 25.2.1 requires scipy>=1.8.0, which is not installed.\n",
            "tensorflow-decision-forests 1.11.0 requires pandas, which is not installed.\n",
            "geopandas 1.0.1 requires pandas>=1.4.0, which is not installed.\n",
            "hyperopt 0.2.7 requires scipy, which is not installed.\n",
            "umap-learn 0.5.7 requires scipy>=1.3.1, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.2\n",
            "Collecting pandas==2.2.2\n",
            "  Using cached pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (1.26.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n",
            "Using cached pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "Installing collected packages: pandas\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mlxtend 0.23.4 requires scipy>=1.2.1, which is not installed.\n",
            "pymc 5.21.2 requires scipy>=1.4.1, which is not installed.\n",
            "arviz 0.21.0 requires scipy>=1.9.0, which is not installed.\n",
            "shap 0.47.1 requires scipy, which is not installed.\n",
            "datascience 0.17.6 requires scipy, which is not installed.\n",
            "mizani 0.13.2 requires scipy>=1.8.0, which is not installed.\n",
            "statsmodels 0.14.4 requires scipy!=1.9.2,>=1.8, which is not installed.\n",
            "plotnine 0.14.5 requires scipy>=1.8.0, which is not installed.\n",
            "sklearn-pandas 2.2.0 requires scipy>=1.5.1, which is not installed.\n",
            "fastai 2.7.19 requires scipy, which is not installed.\n",
            "fastai 2.7.19 requires spacy<4, which is not installed.\n",
            "missingno 0.5.2 requires scipy, which is not installed.\n",
            "cuml-cu12 25.2.1 requires scipy>=1.8.0, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-2.2.2\n",
            "Collecting thinc==8.3.6\n",
            "  Using cached thinc-8.3.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Collecting blis<1.4.0,>=1.3.0 (from thinc==8.3.6)\n",
            "  Using cached blis-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from thinc==8.3.6) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from thinc==8.3.6) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from thinc==8.3.6) (3.0.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.8.1 in /usr/local/lib/python3.11/dist-packages (from thinc==8.3.6) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from thinc==8.3.6) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /usr/local/lib/python3.11/dist-packages (from thinc==8.3.6) (2.0.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc==8.3.6) (0.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from thinc==8.3.6) (75.2.0)\n",
            "Collecting numpy<3.0.0,>=2.0.0 (from thinc==8.3.6)\n",
            "  Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from thinc==8.3.6) (2.11.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from thinc==8.3.6) (24.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->thinc==8.3.6) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->thinc==8.3.6) (2.33.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->thinc==8.3.6) (4.13.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->thinc==8.3.6) (0.4.0)\n",
            "Using cached thinc-8.3.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "Using cached blis-1.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
            "Using cached numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Installing collected packages: numpy, blis, thinc\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.2\n",
            "    Uninstalling numpy-1.26.2:\n",
            "      Successfully uninstalled numpy-1.26.2\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 0.7.11\n",
            "    Uninstalling blis-0.7.11:\n",
            "      Successfully uninstalled blis-0.7.11\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scs 3.2.7.post2 requires scipy, which is not installed.\n",
            "jaxlib 0.5.1 requires scipy>=1.11.1, which is not installed.\n",
            "treelite 4.4.1 requires scipy, which is not installed.\n",
            "matplotlib-venn 1.1.2 requires scipy, which is not installed.\n",
            "mlxtend 0.23.4 requires scipy>=1.2.1, which is not installed.\n",
            "pymc 5.21.2 requires scipy>=1.4.1, which is not installed.\n",
            "clarabel 0.10.0 requires scipy, which is not installed.\n",
            "osqp 1.0.3 requires scipy>=0.13.2, which is not installed.\n",
            "arviz 0.21.0 requires scipy>=1.9.0, which is not installed.\n",
            "lightgbm 4.5.0 requires scipy, which is not installed.\n",
            "jax 0.5.2 requires scipy>=1.11.1, which is not installed.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, which is not installed.\n",
            "xarray-einstats 0.8.0 requires scipy>=1.9, which is not installed.\n",
            "cvxpy 1.6.4 requires scipy>=1.11.0, which is not installed.\n",
            "xgboost 2.1.4 requires scipy, which is not installed.\n",
            "hdbscan 0.8.40 requires scipy>=1.0, which is not installed.\n",
            "shap 0.47.1 requires scipy, which is not installed.\n",
            "datascience 0.17.6 requires scipy, which is not installed.\n",
            "yellowbrick 1.5 requires scipy>=1.0.0, which is not installed.\n",
            "pytensor 2.30.2 requires scipy<2,>=1, which is not installed.\n",
            "imbalanced-learn 0.13.0 requires scipy<2,>=1.10.1, which is not installed.\n",
            "albumentations 2.0.5 requires scipy>=1.10.0, which is not installed.\n",
            "mizani 0.13.2 requires scipy>=1.8.0, which is not installed.\n",
            "statsmodels 0.14.4 requires scipy!=1.9.2,>=1.8, which is not installed.\n",
            "plotnine 0.14.5 requires scipy>=1.8.0, which is not installed.\n",
            "librosa 0.11.0 requires scipy>=1.6.0, which is not installed.\n",
            "sklearn-pandas 2.2.0 requires scipy>=1.5.1, which is not installed.\n",
            "fastai 2.7.19 requires scipy, which is not installed.\n",
            "fastai 2.7.19 requires spacy<4, which is not installed.\n",
            "scikit-learn 1.6.1 requires scipy>=1.6.0, which is not installed.\n",
            "missingno 0.5.2 requires scipy, which is not installed.\n",
            "cuml-cu12 25.2.1 requires scipy>=1.8.0, which is not installed.\n",
            "hyperopt 0.2.7 requires scipy, which is not installed.\n",
            "umap-learn 0.5.7 requires scipy>=1.3.1, which is not installed.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed blis-1.3.0 numpy-2.2.4 thinc-8.3.6\n",
            "Collecting spacy==3.7.6\n",
            "  Using cached spacy-3.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.6) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.6) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.6) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.6) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.6) (3.0.9)\n",
            "Collecting thinc<8.3.0,>=8.2.2 (from spacy==3.7.6)\n",
            "  Using cached thinc-8.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.6) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.6) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.6) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.6) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.6) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.6) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.6) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.6) (2.11.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.6) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.6) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.6) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.6) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy==3.7.6) (2.2.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy==3.7.6) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.6) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.6) (2.33.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.6) (4.13.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy==3.7.6) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.6) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.6) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.6) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy==3.7.6) (2025.1.31)\n",
            "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.2.2->spacy==3.7.6)\n",
            "  Using cached blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy==3.7.6) (0.1.5)\n",
            "Collecting numpy>=1.19.0 (from spacy==3.7.6)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy==3.7.6) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy==3.7.6) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy==3.7.6) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy==3.7.6) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy==3.7.6) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy==3.7.6) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy==3.7.6) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy==3.7.6) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy==3.7.6) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy==3.7.6) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy==3.7.6) (0.1.2)\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'spacy' candidate (version 3.7.6 at https://files.pythonhosted.org/packages/89/70/9a54469cf5263d4e4079b329458492a1e150810587b7c82961bee208cfa5/spacy-3.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from https://pypi.org/simple/spacy/) (requires-python:>=3.7))\n",
            "Reason for being yanked: Incorrect compatibility for transformer models\u001b[0m\u001b[33m\n",
            "\u001b[0mUsing cached spacy-3.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30.5 MB)\n",
            "Using cached thinc-8.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (920 kB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Using cached blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
            "Installing collected packages: numpy, blis, thinc, spacy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.4\n",
            "    Uninstalling numpy-2.2.4:\n",
            "      Successfully uninstalled numpy-2.2.4\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 1.3.0\n",
            "    Uninstalling blis-1.3.0:\n",
            "      Successfully uninstalled blis-1.3.0\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.3.6\n",
            "    Uninstalling thinc-8.3.6:\n",
            "      Successfully uninstalled thinc-8.3.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scs 3.2.7.post2 requires scipy, which is not installed.\n",
            "jaxlib 0.5.1 requires scipy>=1.11.1, which is not installed.\n",
            "treelite 4.4.1 requires scipy, which is not installed.\n",
            "matplotlib-venn 1.1.2 requires scipy, which is not installed.\n",
            "mlxtend 0.23.4 requires scipy>=1.2.1, which is not installed.\n",
            "pymc 5.21.2 requires scipy>=1.4.1, which is not installed.\n",
            "clarabel 0.10.0 requires scipy, which is not installed.\n",
            "osqp 1.0.3 requires scipy>=0.13.2, which is not installed.\n",
            "arviz 0.21.0 requires scipy>=1.9.0, which is not installed.\n",
            "lightgbm 4.5.0 requires scipy, which is not installed.\n",
            "jax 0.5.2 requires scipy>=1.11.1, which is not installed.\n",
            "scikit-image 0.25.2 requires scipy>=1.11.4, which is not installed.\n",
            "xarray-einstats 0.8.0 requires scipy>=1.9, which is not installed.\n",
            "cvxpy 1.6.4 requires scipy>=1.11.0, which is not installed.\n",
            "xgboost 2.1.4 requires scipy, which is not installed.\n",
            "hdbscan 0.8.40 requires scipy>=1.0, which is not installed.\n",
            "shap 0.47.1 requires scipy, which is not installed.\n",
            "datascience 0.17.6 requires scipy, which is not installed.\n",
            "yellowbrick 1.5 requires scipy>=1.0.0, which is not installed.\n",
            "pytensor 2.30.2 requires scipy<2,>=1, which is not installed.\n",
            "imbalanced-learn 0.13.0 requires scipy<2,>=1.10.1, which is not installed.\n",
            "albumentations 2.0.5 requires scipy>=1.10.0, which is not installed.\n",
            "mizani 0.13.2 requires scipy>=1.8.0, which is not installed.\n",
            "statsmodels 0.14.4 requires scipy!=1.9.2,>=1.8, which is not installed.\n",
            "plotnine 0.14.5 requires scipy>=1.8.0, which is not installed.\n",
            "librosa 0.11.0 requires scipy>=1.6.0, which is not installed.\n",
            "sklearn-pandas 2.2.0 requires scipy>=1.5.1, which is not installed.\n",
            "fastai 2.7.19 requires scipy, which is not installed.\n",
            "scikit-learn 1.6.1 requires scipy>=1.6.0, which is not installed.\n",
            "missingno 0.5.2 requires scipy, which is not installed.\n",
            "cuml-cu12 25.2.1 requires scipy>=1.8.0, which is not installed.\n",
            "hyperopt 0.2.7 requires scipy, which is not installed.\n",
            "umap-learn 0.5.7 requires scipy>=1.3.1, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed blis-0.7.11 numpy-1.26.4 spacy-3.7.6 thinc-8.2.5\n",
            "Collecting gensim\n",
            "  Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting scipy\n",
            "  Using cached scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "  Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "Installing collected packages: scipy, gensim\n",
            "Successfully installed gensim-4.3.3 scipy-1.13.1\n",
            "NumPy version: 1.26.4\n",
            "Pandas version: 2.2.2\n",
            "Packages imported successfully!\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y numpy pandas thinc spacy gensim scipy\n",
        "\n",
        "# Install numpy compatible with thinc and pandas\n",
        "!pip install numpy==1.26.2\n",
        "\n",
        "# Install pandas required by Google Colab\n",
        "!pip install pandas==2.2.2\n",
        "\n",
        "# Install thinc compatible with spacy\n",
        "!pip install thinc==8.3.6\n",
        "\n",
        "# Install spacy compatible with thinc and numpy\n",
        "!pip install spacy==3.7.6\n",
        "\n",
        "# Reinstall gensim and scipy\n",
        "!pip install gensim scipy\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "import spacy\n",
        "\n",
        "print(\"NumPy version:\", np.__version__)\n",
        "print(\"Pandas version:\", pd.__version__)\n",
        "print(\"Packages imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d1619eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d1619eb",
        "outputId": "554128d6-ecb3-4914-cf18-3cb4115d2293"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample tokens: 0    [nod, stake, sale, hdfc, gen, insurance, insur...\n",
            "1    [citi, cut, job, india, citigroup, inc, say, w...\n",
            "2    [mha, bat, smse, bank, transaction, atm, slip,...\n",
            "3    [federal, bank, get, fipb, nod, raise, foreign...\n",
            "4    [provide, loan, urban, development, evince, in...\n",
            "Name: tokens, dtype: object\n",
            "Word2Vec model trained.\n",
            "Document vectors shape: (29990, 500)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import xgboost as xgb\n",
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "# Load your preprocessed CSV file\n",
        "df = pd.read_csv('labelled_news_sentiment.csv')\n",
        "\n",
        "# Tokenize the processed text\n",
        "df['tokens'] = df['processed_text'].apply(lambda x: x.split())\n",
        "\n",
        "print(\"Sample tokens:\", df['tokens'].head())\n",
        "\n",
        "# Prepare the corpus: a list of token lists\n",
        "corpus = df['tokens'].tolist()\n",
        "\n",
        "# Train the Word2Vec model\n",
        "w2v_model = Word2Vec(sentences=corpus,\n",
        "                     vector_size=500,    # Dimension of the word vectors\n",
        "                     window=10,           # Context window size\n",
        "                     min_count=1,        # Minimum frequency for a word to be considered\n",
        "                     workers=10,          # Number of threads for training\n",
        "                     epochs=30)\n",
        "\n",
        "print(\"Word2Vec model trained.\")\n",
        "\n",
        "# Calculate IDF values for all words in the corpus\n",
        "def calculate_idf(corpus):\n",
        "    \"\"\"\n",
        "    Calculate IDF (Inverse Document Frequency) for each word in the corpus.\n",
        "    \"\"\"\n",
        "    total_documents = len(corpus)\n",
        "    word_document_count = Counter()\n",
        "\n",
        "    # Count how many documents each word appears in\n",
        "    for document in corpus:\n",
        "        unique_words = set(document)\n",
        "        for word in unique_words:\n",
        "            word_document_count[word] += 1\n",
        "\n",
        "    # Calculate IDF using the formula: log(N / (1 + df))\n",
        "    idf_values = {word: math.log(total_documents / (1 + count)) for word, count in word_document_count.items()}\n",
        "    return idf_values\n",
        "\n",
        "idf_values = calculate_idf(corpus)\n",
        "\n",
        "def calculate_tfidf_weighted_doc_vector(tokens, idf_values, w2v_model):\n",
        "    \"\"\"\n",
        "    Calculate TF-IDF weighted average of Word2Vec vectors for a document.\n",
        "\n",
        "    Parameters:\n",
        "    - tokens: List of tokens in the document.\n",
        "    - idf_values: Precomputed IDF values for all words.\n",
        "    - w2v_model: Trained Word2Vec model.\n",
        "\n",
        "    Returns:\n",
        "    - Weighted average vector representation of the document.\n",
        "    \"\"\"\n",
        "    # Calculate term frequency (TF) for this document\n",
        "    tf_values = Counter(tokens)\n",
        "    total_terms = len(tokens)\n",
        "\n",
        "    # Normalize TF by dividing by total terms in the document\n",
        "    tf_values = {word: count / total_terms for word, count in tf_values.items()}\n",
        "\n",
        "    # Initialize variables for weighted vector calculation\n",
        "    weighted_sum = np.zeros(w2v_model.vector_size)\n",
        "    total_weight = 0.0\n",
        "\n",
        "    # Calculate TF-IDF weighted vectors\n",
        "    for token in tokens:\n",
        "        if token in w2v_model.wv and token in idf_values:\n",
        "            tfidf_score = tf_values[token] * idf_values[token]  # TF-IDF score\n",
        "            weighted_sum += w2v_model.wv[token] * tfidf_score  # Weighted vector sum\n",
        "            total_weight += tfidf_score\n",
        "\n",
        "    # Return normalized weighted average vector or zero vector if no valid tokens are found\n",
        "    if total_weight > 0:\n",
        "        return weighted_sum / total_weight\n",
        "    else:\n",
        "        return np.zeros(w2v_model.vector_size)\n",
        "\n",
        "# Generate document vectors using TF-IDF weighting\n",
        "doc_vectors = []\n",
        "for tokens in df['tokens']:\n",
        "    doc_vector = calculate_tfidf_weighted_doc_vector(tokens, idf_values, w2v_model)\n",
        "    doc_vectors.append(doc_vector)\n",
        "\n",
        "doc_vectors = np.array(doc_vectors)\n",
        "print(\"Document vectors shape:\", doc_vectors.shape)\n",
        "\n",
        "X = doc_vectors\n",
        "y = df['news_sentiment'].values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "i2KOUdehyY0m",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2KOUdehyY0m",
        "outputId": "2c97be47-4d0f-421c-8bcc-87d9664726c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X: (29990, 500)\n",
            "Shape of y: (29990,)\n"
          ]
        }
      ],
      "source": [
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Shape of y:\", y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "B4PIAGlt6bfD",
      "metadata": {
        "id": "B4PIAGlt6bfD"
      },
      "source": [
        "# PCA Implementation for Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "s3P8gD-PzG3n",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3P8gD-PzG3n",
        "outputId": "b1174862-57c4-4d46-bb5b-bf7ce18b3072"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after scaling: (29990, 500)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Standardize the document vectors\n",
        "scaler = StandardScaler()\n",
        "doc_vectors_scaled = scaler.fit_transform(doc_vectors)\n",
        "\n",
        "print(\"Shape after scaling:\", doc_vectors_scaled.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZZDJc8EdzG0H",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "ZZDJc8EdzG0H",
        "outputId": "8afeb0ff-a6ee-47cc-cc1d-0f31ff2ecfb5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Initialize PCA and fit it to the scaled data\n",
        "pca = PCA()\n",
        "pca.fit(doc_vectors_scaled)\n",
        "\n",
        "# Plot cumulative explained variance to decide the number of components\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.title('Explained Variance vs Number of Components')\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Hgn8QtDhzGxn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hgn8QtDhzGxn",
        "outputId": "912974f1-a8ee-4cae-ac08-3eb4c579b103"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after PCA: (29990, 100)\n"
          ]
        }
      ],
      "source": [
        "# Set the number of components (e.g., 100)\n",
        "n_components = 100\n",
        "\n",
        "# Apply PCA with the chosen number of components\n",
        "pca = PCA(n_components=n_components)\n",
        "X_reduced = pca.fit_transform(doc_vectors_scaled)\n",
        "\n",
        "print(\"Shape after PCA:\", X_reduced.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IOlMCFSUzYQK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOlMCFSUzYQK",
        "outputId": "56694e65-7e8d-4c8c-ae1f-c3490044dbf1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X_train: (23992, 100)\n",
            "Shape of X_test: (5998, 100)\n",
            "[0]\ttrain-rmse:0.45541\ttest-rmse:0.45452\n",
            "[1]\ttrain-rmse:0.44885\ttest-rmse:0.44857\n",
            "[2]\ttrain-rmse:0.44347\ttest-rmse:0.44405\n",
            "[3]\ttrain-rmse:0.43877\ttest-rmse:0.43983\n",
            "[4]\ttrain-rmse:0.43437\ttest-rmse:0.43658\n",
            "[5]\ttrain-rmse:0.43082\ttest-rmse:0.43368\n",
            "[6]\ttrain-rmse:0.42691\ttest-rmse:0.43098\n",
            "[7]\ttrain-rmse:0.42327\ttest-rmse:0.42853\n",
            "[8]\ttrain-rmse:0.42010\ttest-rmse:0.42613\n",
            "[9]\ttrain-rmse:0.41732\ttest-rmse:0.42401\n",
            "[10]\ttrain-rmse:0.41446\ttest-rmse:0.42218\n",
            "[11]\ttrain-rmse:0.41179\ttest-rmse:0.42033\n",
            "[12]\ttrain-rmse:0.40920\ttest-rmse:0.41832\n",
            "[13]\ttrain-rmse:0.40691\ttest-rmse:0.41666\n",
            "[14]\ttrain-rmse:0.40477\ttest-rmse:0.41519\n",
            "[15]\ttrain-rmse:0.40267\ttest-rmse:0.41354\n",
            "[16]\ttrain-rmse:0.40059\ttest-rmse:0.41227\n",
            "[17]\ttrain-rmse:0.39848\ttest-rmse:0.41076\n",
            "[18]\ttrain-rmse:0.39661\ttest-rmse:0.40957\n",
            "[19]\ttrain-rmse:0.39464\ttest-rmse:0.40864\n",
            "[20]\ttrain-rmse:0.39291\ttest-rmse:0.40731\n",
            "[21]\ttrain-rmse:0.39116\ttest-rmse:0.40619\n",
            "[22]\ttrain-rmse:0.38943\ttest-rmse:0.40519\n",
            "[23]\ttrain-rmse:0.38788\ttest-rmse:0.40424\n",
            "[24]\ttrain-rmse:0.38635\ttest-rmse:0.40336\n",
            "[25]\ttrain-rmse:0.38480\ttest-rmse:0.40256\n",
            "[26]\ttrain-rmse:0.38336\ttest-rmse:0.40183\n",
            "[27]\ttrain-rmse:0.38182\ttest-rmse:0.40092\n",
            "[28]\ttrain-rmse:0.38038\ttest-rmse:0.40002\n",
            "[29]\ttrain-rmse:0.37919\ttest-rmse:0.39920\n",
            "[30]\ttrain-rmse:0.37798\ttest-rmse:0.39853\n",
            "[31]\ttrain-rmse:0.37678\ttest-rmse:0.39792\n",
            "[32]\ttrain-rmse:0.37561\ttest-rmse:0.39737\n",
            "[33]\ttrain-rmse:0.37445\ttest-rmse:0.39686\n",
            "[34]\ttrain-rmse:0.37326\ttest-rmse:0.39623\n",
            "[35]\ttrain-rmse:0.37204\ttest-rmse:0.39561\n",
            "[36]\ttrain-rmse:0.37088\ttest-rmse:0.39519\n",
            "[37]\ttrain-rmse:0.36972\ttest-rmse:0.39459\n",
            "[38]\ttrain-rmse:0.36863\ttest-rmse:0.39389\n",
            "[39]\ttrain-rmse:0.36756\ttest-rmse:0.39341\n",
            "[40]\ttrain-rmse:0.36661\ttest-rmse:0.39285\n",
            "[41]\ttrain-rmse:0.36546\ttest-rmse:0.39219\n",
            "[42]\ttrain-rmse:0.36439\ttest-rmse:0.39182\n",
            "[43]\ttrain-rmse:0.36343\ttest-rmse:0.39148\n",
            "[44]\ttrain-rmse:0.36239\ttest-rmse:0.39096\n",
            "[45]\ttrain-rmse:0.36142\ttest-rmse:0.39046\n",
            "[46]\ttrain-rmse:0.36054\ttest-rmse:0.39021\n",
            "[47]\ttrain-rmse:0.35961\ttest-rmse:0.38990\n",
            "[48]\ttrain-rmse:0.35868\ttest-rmse:0.38935\n",
            "[49]\ttrain-rmse:0.35780\ttest-rmse:0.38887\n",
            "[50]\ttrain-rmse:0.35686\ttest-rmse:0.38852\n",
            "[51]\ttrain-rmse:0.35602\ttest-rmse:0.38813\n",
            "[52]\ttrain-rmse:0.35517\ttest-rmse:0.38787\n",
            "[53]\ttrain-rmse:0.35442\ttest-rmse:0.38755\n",
            "[54]\ttrain-rmse:0.35362\ttest-rmse:0.38727\n",
            "[55]\ttrain-rmse:0.35271\ttest-rmse:0.38672\n",
            "[56]\ttrain-rmse:0.35203\ttest-rmse:0.38630\n",
            "[57]\ttrain-rmse:0.35129\ttest-rmse:0.38606\n",
            "[58]\ttrain-rmse:0.35048\ttest-rmse:0.38576\n",
            "[59]\ttrain-rmse:0.34971\ttest-rmse:0.38564\n",
            "[60]\ttrain-rmse:0.34888\ttest-rmse:0.38512\n",
            "[61]\ttrain-rmse:0.34804\ttest-rmse:0.38485\n",
            "[62]\ttrain-rmse:0.34733\ttest-rmse:0.38435\n",
            "[63]\ttrain-rmse:0.34659\ttest-rmse:0.38409\n",
            "[64]\ttrain-rmse:0.34591\ttest-rmse:0.38387\n",
            "[65]\ttrain-rmse:0.34531\ttest-rmse:0.38360\n",
            "[66]\ttrain-rmse:0.34456\ttest-rmse:0.38326\n",
            "[67]\ttrain-rmse:0.34391\ttest-rmse:0.38290\n",
            "[68]\ttrain-rmse:0.34323\ttest-rmse:0.38266\n",
            "[69]\ttrain-rmse:0.34249\ttest-rmse:0.38230\n",
            "[70]\ttrain-rmse:0.34172\ttest-rmse:0.38217\n",
            "[71]\ttrain-rmse:0.34102\ttest-rmse:0.38202\n",
            "[72]\ttrain-rmse:0.34025\ttest-rmse:0.38175\n",
            "[73]\ttrain-rmse:0.33955\ttest-rmse:0.38148\n",
            "[74]\ttrain-rmse:0.33895\ttest-rmse:0.38138\n",
            "[75]\ttrain-rmse:0.33828\ttest-rmse:0.38123\n",
            "[76]\ttrain-rmse:0.33758\ttest-rmse:0.38106\n",
            "[77]\ttrain-rmse:0.33692\ttest-rmse:0.38079\n",
            "[78]\ttrain-rmse:0.33630\ttest-rmse:0.38053\n",
            "[79]\ttrain-rmse:0.33573\ttest-rmse:0.38046\n",
            "[80]\ttrain-rmse:0.33508\ttest-rmse:0.38041\n",
            "[81]\ttrain-rmse:0.33463\ttest-rmse:0.38026\n",
            "[82]\ttrain-rmse:0.33406\ttest-rmse:0.38020\n",
            "[83]\ttrain-rmse:0.33345\ttest-rmse:0.38006\n",
            "[84]\ttrain-rmse:0.33290\ttest-rmse:0.38002\n",
            "[85]\ttrain-rmse:0.33233\ttest-rmse:0.37982\n",
            "[86]\ttrain-rmse:0.33170\ttest-rmse:0.37966\n",
            "[87]\ttrain-rmse:0.33109\ttest-rmse:0.37950\n",
            "[88]\ttrain-rmse:0.33044\ttest-rmse:0.37944\n",
            "[89]\ttrain-rmse:0.32991\ttest-rmse:0.37937\n",
            "[90]\ttrain-rmse:0.32929\ttest-rmse:0.37909\n",
            "[91]\ttrain-rmse:0.32872\ttest-rmse:0.37887\n",
            "[92]\ttrain-rmse:0.32814\ttest-rmse:0.37881\n",
            "[93]\ttrain-rmse:0.32757\ttest-rmse:0.37867\n",
            "[94]\ttrain-rmse:0.32704\ttest-rmse:0.37852\n",
            "[95]\ttrain-rmse:0.32645\ttest-rmse:0.37834\n",
            "[96]\ttrain-rmse:0.32591\ttest-rmse:0.37831\n",
            "[97]\ttrain-rmse:0.32527\ttest-rmse:0.37815\n",
            "[98]\ttrain-rmse:0.32478\ttest-rmse:0.37802\n",
            "[99]\ttrain-rmse:0.32425\ttest-rmse:0.37786\n",
            "\n",
            "Final Evaluation Metrics:\n",
            "Mean Absolute Error (MAE): 0.2778\n",
            "Mean Absolute Average (MAA): 0.3045\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import xgboost as xgb\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "\n",
        "# Convert to DMatrix format for XGBoost\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "# Set parameters for XGBoost regression\n",
        "params = {\n",
        "    'objective': 'reg:squarederror',\n",
        "    'max_depth': 5,\n",
        "    'eta': 0.1,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8\n",
        "}\n",
        "\n",
        "# Train the model with early stopping\n",
        "xgb_model = xgb.train(params, dtrain, num_boost_round=100,\n",
        "                      evals=[(dtrain, 'train'), (dtest, 'test')],\n",
        "                      early_stopping_rounds=10, verbose_eval=True)\n",
        "\n",
        "# Use the trained model for predictions\n",
        "y_pred = xgb_model.predict(dtest)\n",
        "\n",
        "# Calculate Mean Absolute Error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"\\nFinal Evaluation Metrics:\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "maa = np.mean(np.abs(y_test))\n",
        "print(f\"Mean Absolute Average (MAA): {maa:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f-vO-Qz96n3x",
      "metadata": {
        "id": "f-vO-Qz96n3x"
      },
      "source": [
        "# Implementing various Feature Selection Techniques\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Rsw4jpIC2aDm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rsw4jpIC2aDm",
        "outputId": "ce3a20b4-ee57-46a2-ddce-d21a92ba11c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after low variance filter: (29990, 382)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "\n",
        "# Set a threshold for variance (e.g., 0.01)\n",
        "threshold = 0.08\n",
        "selector = VarianceThreshold(threshold=threshold)\n",
        "\n",
        "# Apply the filter\n",
        "X_low_variance = selector.fit_transform(doc_vectors)\n",
        "\n",
        "print(\"Shape after low variance filter:\", X_low_variance.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gEQubUHa3K1p",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEQubUHa3K1p",
        "outputId": "087962ef-4ba1-43e9-d8ef-107ccdea13d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Highly correlated feature pairs: []\n",
            "Shape after high correlation filter: (29990, 500)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Convert document vectors to a DataFrame for easier manipulation\n",
        "df_features = pd.DataFrame(doc_vectors)\n",
        "\n",
        "# Compute the correlation matrix\n",
        "correlation_matrix = df_features.corr()\n",
        "\n",
        "# Identify highly correlated features (e.g., correlation > 0.9)\n",
        "high_corr_pairs = np.where(np.abs(correlation_matrix) > 0.9)\n",
        "high_corr_pairs = [(i, j) for i, j in zip(*high_corr_pairs) if i != j and i < j]\n",
        "\n",
        "print(\"Highly correlated feature pairs:\", high_corr_pairs)\n",
        "\n",
        "# Drop one feature from each pair of highly correlated features\n",
        "features_to_drop = set()\n",
        "for i, j in high_corr_pairs:\n",
        "    features_to_drop.add(j)  # Arbitrarily drop the second feature in each pair\n",
        "\n",
        "df_features_filtered = df_features.drop(columns=list(features_to_drop))\n",
        "\n",
        "print(\"Shape after high correlation filter:\", df_features_filtered.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yGBnyJxN3Zz0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGBnyJxN3Zz0",
        "outputId": "33453de6-2bbb-4e75-eceb-764eb58174e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape after Lasso feature selection: (29990, 74)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Standardize the data before applying Lasso\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(doc_vectors)\n",
        "\n",
        "# Fit Lasso regression with regularization parameter alpha\n",
        "lasso = Lasso(alpha=0.01)  # Adjust alpha based on your dataset\n",
        "lasso.fit(X_scaled, y)\n",
        "\n",
        "# Get selected features (non-zero coefficients)\n",
        "selected_features = np.where(lasso.coef_ != 0)[0]\n",
        "X_lasso_selected = X_scaled[:, selected_features]\n",
        "\n",
        "print(\"Shape after Lasso feature selection:\", X_lasso_selected.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FwkiZm0I4hfw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwkiZm0I4hfw",
        "outputId": "5980a4ee-9553-4cf7-d470-6d4f53caddbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X_train: (23992, 382)\n",
            "Shape of X_test: (5998, 382)\n",
            "[0]\ttrain-rmse:0.45304\ttest-rmse:0.45230\n",
            "[1]\ttrain-rmse:0.44602\ttest-rmse:0.44618\n",
            "[2]\ttrain-rmse:0.43985\ttest-rmse:0.44121\n",
            "[3]\ttrain-rmse:0.43403\ttest-rmse:0.43650\n",
            "[4]\ttrain-rmse:0.42870\ttest-rmse:0.43223\n",
            "[5]\ttrain-rmse:0.42397\ttest-rmse:0.42839\n",
            "[6]\ttrain-rmse:0.41972\ttest-rmse:0.42515\n",
            "[7]\ttrain-rmse:0.41557\ttest-rmse:0.42185\n",
            "[8]\ttrain-rmse:0.41186\ttest-rmse:0.41928\n",
            "[9]\ttrain-rmse:0.40814\ttest-rmse:0.41652\n",
            "[10]\ttrain-rmse:0.40497\ttest-rmse:0.41414\n",
            "[11]\ttrain-rmse:0.40168\ttest-rmse:0.41187\n",
            "[12]\ttrain-rmse:0.39839\ttest-rmse:0.40957\n",
            "[13]\ttrain-rmse:0.39544\ttest-rmse:0.40756\n",
            "[14]\ttrain-rmse:0.39269\ttest-rmse:0.40572\n",
            "[15]\ttrain-rmse:0.39001\ttest-rmse:0.40389\n",
            "[16]\ttrain-rmse:0.38760\ttest-rmse:0.40219\n",
            "[17]\ttrain-rmse:0.38538\ttest-rmse:0.40099\n",
            "[18]\ttrain-rmse:0.38304\ttest-rmse:0.39964\n",
            "[19]\ttrain-rmse:0.38110\ttest-rmse:0.39850\n",
            "[20]\ttrain-rmse:0.37910\ttest-rmse:0.39721\n",
            "[21]\ttrain-rmse:0.37723\ttest-rmse:0.39601\n",
            "[22]\ttrain-rmse:0.37534\ttest-rmse:0.39495\n",
            "[23]\ttrain-rmse:0.37350\ttest-rmse:0.39378\n",
            "[24]\ttrain-rmse:0.37187\ttest-rmse:0.39286\n",
            "[25]\ttrain-rmse:0.37026\ttest-rmse:0.39179\n",
            "[26]\ttrain-rmse:0.36887\ttest-rmse:0.39109\n",
            "[27]\ttrain-rmse:0.36733\ttest-rmse:0.39029\n",
            "[28]\ttrain-rmse:0.36582\ttest-rmse:0.38956\n",
            "[29]\ttrain-rmse:0.36431\ttest-rmse:0.38887\n",
            "[30]\ttrain-rmse:0.36289\ttest-rmse:0.38830\n",
            "[31]\ttrain-rmse:0.36142\ttest-rmse:0.38743\n",
            "[32]\ttrain-rmse:0.36009\ttest-rmse:0.38690\n",
            "[33]\ttrain-rmse:0.35869\ttest-rmse:0.38623\n",
            "[34]\ttrain-rmse:0.35745\ttest-rmse:0.38557\n",
            "[35]\ttrain-rmse:0.35623\ttest-rmse:0.38497\n",
            "[36]\ttrain-rmse:0.35510\ttest-rmse:0.38461\n",
            "[37]\ttrain-rmse:0.35383\ttest-rmse:0.38424\n",
            "[38]\ttrain-rmse:0.35267\ttest-rmse:0.38383\n",
            "[39]\ttrain-rmse:0.35157\ttest-rmse:0.38344\n",
            "[40]\ttrain-rmse:0.35053\ttest-rmse:0.38289\n",
            "[41]\ttrain-rmse:0.34939\ttest-rmse:0.38233\n",
            "[42]\ttrain-rmse:0.34829\ttest-rmse:0.38192\n",
            "[43]\ttrain-rmse:0.34717\ttest-rmse:0.38146\n",
            "[44]\ttrain-rmse:0.34605\ttest-rmse:0.38101\n",
            "[45]\ttrain-rmse:0.34505\ttest-rmse:0.38052\n",
            "[46]\ttrain-rmse:0.34418\ttest-rmse:0.38023\n",
            "[47]\ttrain-rmse:0.34328\ttest-rmse:0.37977\n",
            "[48]\ttrain-rmse:0.34230\ttest-rmse:0.37947\n",
            "[49]\ttrain-rmse:0.34129\ttest-rmse:0.37900\n",
            "[50]\ttrain-rmse:0.34037\ttest-rmse:0.37864\n",
            "[51]\ttrain-rmse:0.33942\ttest-rmse:0.37849\n",
            "[52]\ttrain-rmse:0.33861\ttest-rmse:0.37826\n",
            "[53]\ttrain-rmse:0.33773\ttest-rmse:0.37800\n",
            "[54]\ttrain-rmse:0.33689\ttest-rmse:0.37783\n",
            "[55]\ttrain-rmse:0.33603\ttest-rmse:0.37754\n",
            "[56]\ttrain-rmse:0.33510\ttest-rmse:0.37696\n",
            "[57]\ttrain-rmse:0.33425\ttest-rmse:0.37675\n",
            "[58]\ttrain-rmse:0.33353\ttest-rmse:0.37658\n",
            "[59]\ttrain-rmse:0.33275\ttest-rmse:0.37656\n",
            "[60]\ttrain-rmse:0.33192\ttest-rmse:0.37629\n",
            "[61]\ttrain-rmse:0.33112\ttest-rmse:0.37596\n",
            "[62]\ttrain-rmse:0.33032\ttest-rmse:0.37572\n",
            "[63]\ttrain-rmse:0.32947\ttest-rmse:0.37545\n",
            "[64]\ttrain-rmse:0.32878\ttest-rmse:0.37535\n",
            "[65]\ttrain-rmse:0.32794\ttest-rmse:0.37506\n",
            "[66]\ttrain-rmse:0.32739\ttest-rmse:0.37496\n",
            "[67]\ttrain-rmse:0.32664\ttest-rmse:0.37476\n",
            "[68]\ttrain-rmse:0.32590\ttest-rmse:0.37441\n",
            "[69]\ttrain-rmse:0.32519\ttest-rmse:0.37411\n",
            "[70]\ttrain-rmse:0.32447\ttest-rmse:0.37401\n",
            "[71]\ttrain-rmse:0.32381\ttest-rmse:0.37384\n",
            "[72]\ttrain-rmse:0.32321\ttest-rmse:0.37371\n",
            "[73]\ttrain-rmse:0.32251\ttest-rmse:0.37350\n",
            "[74]\ttrain-rmse:0.32175\ttest-rmse:0.37321\n",
            "[75]\ttrain-rmse:0.32112\ttest-rmse:0.37309\n",
            "[76]\ttrain-rmse:0.32037\ttest-rmse:0.37296\n",
            "[77]\ttrain-rmse:0.31975\ttest-rmse:0.37278\n",
            "[78]\ttrain-rmse:0.31911\ttest-rmse:0.37262\n",
            "[79]\ttrain-rmse:0.31825\ttest-rmse:0.37245\n",
            "[80]\ttrain-rmse:0.31765\ttest-rmse:0.37226\n",
            "[81]\ttrain-rmse:0.31709\ttest-rmse:0.37213\n",
            "[82]\ttrain-rmse:0.31669\ttest-rmse:0.37203\n",
            "[83]\ttrain-rmse:0.31596\ttest-rmse:0.37187\n",
            "[84]\ttrain-rmse:0.31533\ttest-rmse:0.37171\n",
            "[85]\ttrain-rmse:0.31463\ttest-rmse:0.37146\n",
            "[86]\ttrain-rmse:0.31405\ttest-rmse:0.37136\n",
            "[87]\ttrain-rmse:0.31342\ttest-rmse:0.37103\n",
            "[88]\ttrain-rmse:0.31279\ttest-rmse:0.37084\n",
            "[89]\ttrain-rmse:0.31214\ttest-rmse:0.37075\n",
            "[90]\ttrain-rmse:0.31165\ttest-rmse:0.37066\n",
            "[91]\ttrain-rmse:0.31100\ttest-rmse:0.37059\n",
            "[92]\ttrain-rmse:0.31044\ttest-rmse:0.37034\n",
            "[93]\ttrain-rmse:0.30977\ttest-rmse:0.37015\n",
            "[94]\ttrain-rmse:0.30918\ttest-rmse:0.37012\n",
            "[95]\ttrain-rmse:0.30849\ttest-rmse:0.37004\n",
            "[96]\ttrain-rmse:0.30797\ttest-rmse:0.37004\n",
            "[97]\ttrain-rmse:0.30742\ttest-rmse:0.36987\n",
            "[98]\ttrain-rmse:0.30690\ttest-rmse:0.36989\n",
            "[99]\ttrain-rmse:0.30646\ttest-rmse:0.36971\n",
            "\n",
            "Final Evaluation Metrics:\n",
            "Mean Absolute Error (MAE): 0.2699\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import xgboost as xgb\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_low_variance, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "\n",
        "# Convert to DMatrix format for XGBoost\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "# Set parameters for XGBoost regression\n",
        "params = {\n",
        "    'objective': 'reg:squarederror',\n",
        "    'max_depth': 5,\n",
        "    'eta': 0.1,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8\n",
        "}\n",
        "\n",
        "# Train the model with early stopping\n",
        "xgb_model_low_variance = xgb.train(params, dtrain, num_boost_round=100,\n",
        "                      evals=[(dtrain, 'train'), (dtest, 'test')],\n",
        "                      early_stopping_rounds=10, verbose_eval=True)\n",
        "\n",
        "# Use the trained model for predictions\n",
        "y_pred = xgb_model_low_variance.predict(dtest)\n",
        "\n",
        "# Calculate Mean Absolute Error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"\\nFinal Evaluation Metrics:\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hxr0kysj4hWq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxr0kysj4hWq",
        "outputId": "bc98b189-cc96-47a6-c08e-c90f6ad259ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X_train: (23992, 74)\n",
            "Shape of X_test: (5998, 74)\n",
            "[0]\ttrain-rmse:0.45337\ttest-rmse:0.45233\n",
            "[1]\ttrain-rmse:0.44640\ttest-rmse:0.44645\n",
            "[2]\ttrain-rmse:0.43996\ttest-rmse:0.44079\n",
            "[3]\ttrain-rmse:0.43431\ttest-rmse:0.43611\n",
            "[4]\ttrain-rmse:0.42886\ttest-rmse:0.43165\n",
            "[5]\ttrain-rmse:0.42431\ttest-rmse:0.42777\n",
            "[6]\ttrain-rmse:0.42020\ttest-rmse:0.42465\n",
            "[7]\ttrain-rmse:0.41628\ttest-rmse:0.42156\n",
            "[8]\ttrain-rmse:0.41238\ttest-rmse:0.41839\n",
            "[9]\ttrain-rmse:0.40889\ttest-rmse:0.41599\n",
            "[10]\ttrain-rmse:0.40574\ttest-rmse:0.41354\n",
            "[11]\ttrain-rmse:0.40248\ttest-rmse:0.41122\n",
            "[12]\ttrain-rmse:0.39944\ttest-rmse:0.40885\n",
            "[13]\ttrain-rmse:0.39679\ttest-rmse:0.40687\n",
            "[14]\ttrain-rmse:0.39446\ttest-rmse:0.40556\n",
            "[15]\ttrain-rmse:0.39197\ttest-rmse:0.40376\n",
            "[16]\ttrain-rmse:0.38969\ttest-rmse:0.40191\n",
            "[17]\ttrain-rmse:0.38739\ttest-rmse:0.40040\n",
            "[18]\ttrain-rmse:0.38530\ttest-rmse:0.39898\n",
            "[19]\ttrain-rmse:0.38328\ttest-rmse:0.39797\n",
            "[20]\ttrain-rmse:0.38142\ttest-rmse:0.39690\n",
            "[21]\ttrain-rmse:0.37959\ttest-rmse:0.39555\n",
            "[22]\ttrain-rmse:0.37797\ttest-rmse:0.39464\n",
            "[23]\ttrain-rmse:0.37629\ttest-rmse:0.39365\n",
            "[24]\ttrain-rmse:0.37459\ttest-rmse:0.39259\n",
            "[25]\ttrain-rmse:0.37299\ttest-rmse:0.39142\n",
            "[26]\ttrain-rmse:0.37165\ttest-rmse:0.39038\n",
            "[27]\ttrain-rmse:0.37032\ttest-rmse:0.38959\n",
            "[28]\ttrain-rmse:0.36891\ttest-rmse:0.38882\n",
            "[29]\ttrain-rmse:0.36754\ttest-rmse:0.38822\n",
            "[30]\ttrain-rmse:0.36614\ttest-rmse:0.38750\n",
            "[31]\ttrain-rmse:0.36487\ttest-rmse:0.38704\n",
            "[32]\ttrain-rmse:0.36359\ttest-rmse:0.38647\n",
            "[33]\ttrain-rmse:0.36242\ttest-rmse:0.38576\n",
            "[34]\ttrain-rmse:0.36136\ttest-rmse:0.38523\n",
            "[35]\ttrain-rmse:0.36025\ttest-rmse:0.38476\n",
            "[36]\ttrain-rmse:0.35897\ttest-rmse:0.38418\n",
            "[37]\ttrain-rmse:0.35796\ttest-rmse:0.38381\n",
            "[38]\ttrain-rmse:0.35683\ttest-rmse:0.38333\n",
            "[39]\ttrain-rmse:0.35586\ttest-rmse:0.38294\n",
            "[40]\ttrain-rmse:0.35493\ttest-rmse:0.38256\n",
            "[41]\ttrain-rmse:0.35398\ttest-rmse:0.38221\n",
            "[42]\ttrain-rmse:0.35290\ttest-rmse:0.38178\n",
            "[43]\ttrain-rmse:0.35190\ttest-rmse:0.38132\n",
            "[44]\ttrain-rmse:0.35104\ttest-rmse:0.38073\n",
            "[45]\ttrain-rmse:0.35013\ttest-rmse:0.38019\n",
            "[46]\ttrain-rmse:0.34927\ttest-rmse:0.37989\n",
            "[47]\ttrain-rmse:0.34838\ttest-rmse:0.37948\n",
            "[48]\ttrain-rmse:0.34759\ttest-rmse:0.37913\n",
            "[49]\ttrain-rmse:0.34665\ttest-rmse:0.37879\n",
            "[50]\ttrain-rmse:0.34590\ttest-rmse:0.37847\n",
            "[51]\ttrain-rmse:0.34509\ttest-rmse:0.37808\n",
            "[52]\ttrain-rmse:0.34429\ttest-rmse:0.37773\n",
            "[53]\ttrain-rmse:0.34352\ttest-rmse:0.37746\n",
            "[54]\ttrain-rmse:0.34276\ttest-rmse:0.37720\n",
            "[55]\ttrain-rmse:0.34196\ttest-rmse:0.37697\n",
            "[56]\ttrain-rmse:0.34123\ttest-rmse:0.37681\n",
            "[57]\ttrain-rmse:0.34047\ttest-rmse:0.37660\n",
            "[58]\ttrain-rmse:0.33979\ttest-rmse:0.37630\n",
            "[59]\ttrain-rmse:0.33913\ttest-rmse:0.37611\n",
            "[60]\ttrain-rmse:0.33837\ttest-rmse:0.37574\n",
            "[61]\ttrain-rmse:0.33774\ttest-rmse:0.37539\n",
            "[62]\ttrain-rmse:0.33717\ttest-rmse:0.37528\n",
            "[63]\ttrain-rmse:0.33660\ttest-rmse:0.37524\n",
            "[64]\ttrain-rmse:0.33611\ttest-rmse:0.37505\n",
            "[65]\ttrain-rmse:0.33538\ttest-rmse:0.37477\n",
            "[66]\ttrain-rmse:0.33477\ttest-rmse:0.37456\n",
            "[67]\ttrain-rmse:0.33418\ttest-rmse:0.37432\n",
            "[68]\ttrain-rmse:0.33358\ttest-rmse:0.37398\n",
            "[69]\ttrain-rmse:0.33304\ttest-rmse:0.37394\n",
            "[70]\ttrain-rmse:0.33244\ttest-rmse:0.37368\n",
            "[71]\ttrain-rmse:0.33181\ttest-rmse:0.37346\n",
            "[72]\ttrain-rmse:0.33125\ttest-rmse:0.37319\n",
            "[73]\ttrain-rmse:0.33067\ttest-rmse:0.37303\n",
            "[74]\ttrain-rmse:0.33010\ttest-rmse:0.37287\n",
            "[75]\ttrain-rmse:0.32948\ttest-rmse:0.37261\n",
            "[76]\ttrain-rmse:0.32893\ttest-rmse:0.37257\n",
            "[77]\ttrain-rmse:0.32841\ttest-rmse:0.37250\n",
            "[78]\ttrain-rmse:0.32786\ttest-rmse:0.37228\n",
            "[79]\ttrain-rmse:0.32739\ttest-rmse:0.37208\n",
            "[80]\ttrain-rmse:0.32687\ttest-rmse:0.37187\n",
            "[81]\ttrain-rmse:0.32630\ttest-rmse:0.37170\n",
            "[82]\ttrain-rmse:0.32573\ttest-rmse:0.37156\n",
            "[83]\ttrain-rmse:0.32518\ttest-rmse:0.37145\n",
            "[84]\ttrain-rmse:0.32470\ttest-rmse:0.37134\n",
            "[85]\ttrain-rmse:0.32418\ttest-rmse:0.37119\n",
            "[86]\ttrain-rmse:0.32364\ttest-rmse:0.37103\n",
            "[87]\ttrain-rmse:0.32325\ttest-rmse:0.37085\n",
            "[88]\ttrain-rmse:0.32285\ttest-rmse:0.37074\n",
            "[89]\ttrain-rmse:0.32238\ttest-rmse:0.37063\n",
            "[90]\ttrain-rmse:0.32187\ttest-rmse:0.37046\n",
            "[91]\ttrain-rmse:0.32144\ttest-rmse:0.37029\n",
            "[92]\ttrain-rmse:0.32104\ttest-rmse:0.37007\n",
            "[93]\ttrain-rmse:0.32055\ttest-rmse:0.36994\n",
            "[94]\ttrain-rmse:0.32026\ttest-rmse:0.36990\n",
            "[95]\ttrain-rmse:0.31982\ttest-rmse:0.36976\n",
            "[96]\ttrain-rmse:0.31945\ttest-rmse:0.36968\n",
            "[97]\ttrain-rmse:0.31908\ttest-rmse:0.36960\n",
            "[98]\ttrain-rmse:0.31866\ttest-rmse:0.36954\n",
            "[99]\ttrain-rmse:0.31826\ttest-rmse:0.36961\n",
            "\n",
            "Final Evaluation Metrics:\n",
            "Mean Absolute Error (MAE): 0.2729\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import xgboost as xgb\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_lasso_selected, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "\n",
        "# Convert to DMatrix format for XGBoost\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "# Set parameters for XGBoost regression\n",
        "params = {\n",
        "    'objective': 'reg:squarederror',\n",
        "    'max_depth': 5,\n",
        "    'eta': 0.1,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8\n",
        "}\n",
        "\n",
        "# Train the model with early stopping\n",
        "xgb_model_lasso_reg = xgb.train(params, dtrain, num_boost_round=100,\n",
        "                      evals=[(dtrain, 'train'), (dtest, 'test')],\n",
        "                      early_stopping_rounds=10, verbose_eval=True)\n",
        "\n",
        "# Use the trained model for predictions\n",
        "y_pred = xgb_model_lasso_reg.predict(dtest)\n",
        "\n",
        "# Calculate Mean Absolute Error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"\\nFinal Evaluation Metrics:\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jImi42sSyYxV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jImi42sSyYxV",
        "outputId": "ddb38d7d-bb87-41ed-8860-518c19a249e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X_train: (23992, 500)\n",
            "Shape of X_test: (5998, 500)\n",
            "[0]\ttrain-rmse:0.45307\ttest-rmse:0.45230\n",
            "[1]\ttrain-rmse:0.44587\ttest-rmse:0.44617\n",
            "[2]\ttrain-rmse:0.43969\ttest-rmse:0.44122\n",
            "[3]\ttrain-rmse:0.43394\ttest-rmse:0.43644\n",
            "[4]\ttrain-rmse:0.42828\ttest-rmse:0.43175\n",
            "[5]\ttrain-rmse:0.42323\ttest-rmse:0.42755\n",
            "[6]\ttrain-rmse:0.41839\ttest-rmse:0.42388\n",
            "[7]\ttrain-rmse:0.41397\ttest-rmse:0.42064\n",
            "[8]\ttrain-rmse:0.41013\ttest-rmse:0.41775\n",
            "[9]\ttrain-rmse:0.40647\ttest-rmse:0.41522\n",
            "[10]\ttrain-rmse:0.40301\ttest-rmse:0.41276\n",
            "[11]\ttrain-rmse:0.39970\ttest-rmse:0.41073\n",
            "[12]\ttrain-rmse:0.39672\ttest-rmse:0.40841\n",
            "[13]\ttrain-rmse:0.39380\ttest-rmse:0.40623\n",
            "[14]\ttrain-rmse:0.39110\ttest-rmse:0.40440\n",
            "[15]\ttrain-rmse:0.38833\ttest-rmse:0.40266\n",
            "[16]\ttrain-rmse:0.38602\ttest-rmse:0.40110\n",
            "[17]\ttrain-rmse:0.38375\ttest-rmse:0.39979\n",
            "[18]\ttrain-rmse:0.38132\ttest-rmse:0.39796\n",
            "[19]\ttrain-rmse:0.37919\ttest-rmse:0.39668\n",
            "[20]\ttrain-rmse:0.37706\ttest-rmse:0.39517\n",
            "[21]\ttrain-rmse:0.37504\ttest-rmse:0.39396\n",
            "[22]\ttrain-rmse:0.37307\ttest-rmse:0.39267\n",
            "[23]\ttrain-rmse:0.37135\ttest-rmse:0.39173\n",
            "[24]\ttrain-rmse:0.36952\ttest-rmse:0.39091\n",
            "[25]\ttrain-rmse:0.36792\ttest-rmse:0.38997\n",
            "[26]\ttrain-rmse:0.36609\ttest-rmse:0.38918\n",
            "[27]\ttrain-rmse:0.36446\ttest-rmse:0.38848\n",
            "[28]\ttrain-rmse:0.36304\ttest-rmse:0.38772\n",
            "[29]\ttrain-rmse:0.36161\ttest-rmse:0.38698\n",
            "[30]\ttrain-rmse:0.36004\ttest-rmse:0.38624\n",
            "[31]\ttrain-rmse:0.35859\ttest-rmse:0.38534\n",
            "[32]\ttrain-rmse:0.35728\ttest-rmse:0.38479\n",
            "[33]\ttrain-rmse:0.35586\ttest-rmse:0.38404\n",
            "[34]\ttrain-rmse:0.35460\ttest-rmse:0.38353\n",
            "[35]\ttrain-rmse:0.35330\ttest-rmse:0.38293\n",
            "[36]\ttrain-rmse:0.35202\ttest-rmse:0.38235\n",
            "[37]\ttrain-rmse:0.35073\ttest-rmse:0.38171\n",
            "[38]\ttrain-rmse:0.34956\ttest-rmse:0.38118\n",
            "[39]\ttrain-rmse:0.34837\ttest-rmse:0.38069\n",
            "[40]\ttrain-rmse:0.34717\ttest-rmse:0.38019\n",
            "[41]\ttrain-rmse:0.34601\ttest-rmse:0.37992\n",
            "[42]\ttrain-rmse:0.34489\ttest-rmse:0.37941\n",
            "[43]\ttrain-rmse:0.34377\ttest-rmse:0.37882\n",
            "[44]\ttrain-rmse:0.34287\ttest-rmse:0.37847\n",
            "[45]\ttrain-rmse:0.34185\ttest-rmse:0.37768\n",
            "[46]\ttrain-rmse:0.34071\ttest-rmse:0.37716\n",
            "[47]\ttrain-rmse:0.33976\ttest-rmse:0.37673\n",
            "[48]\ttrain-rmse:0.33875\ttest-rmse:0.37640\n",
            "[49]\ttrain-rmse:0.33776\ttest-rmse:0.37600\n",
            "[50]\ttrain-rmse:0.33689\ttest-rmse:0.37573\n",
            "[51]\ttrain-rmse:0.33603\ttest-rmse:0.37527\n",
            "[52]\ttrain-rmse:0.33505\ttest-rmse:0.37502\n",
            "[53]\ttrain-rmse:0.33414\ttest-rmse:0.37473\n",
            "[54]\ttrain-rmse:0.33322\ttest-rmse:0.37462\n",
            "[55]\ttrain-rmse:0.33242\ttest-rmse:0.37431\n",
            "[56]\ttrain-rmse:0.33156\ttest-rmse:0.37408\n",
            "[57]\ttrain-rmse:0.33075\ttest-rmse:0.37380\n",
            "[58]\ttrain-rmse:0.32990\ttest-rmse:0.37362\n",
            "[59]\ttrain-rmse:0.32903\ttest-rmse:0.37323\n",
            "[60]\ttrain-rmse:0.32814\ttest-rmse:0.37298\n",
            "[61]\ttrain-rmse:0.32730\ttest-rmse:0.37271\n",
            "[62]\ttrain-rmse:0.32647\ttest-rmse:0.37260\n",
            "[63]\ttrain-rmse:0.32578\ttest-rmse:0.37256\n",
            "[64]\ttrain-rmse:0.32495\ttest-rmse:0.37233\n",
            "[65]\ttrain-rmse:0.32430\ttest-rmse:0.37216\n",
            "[66]\ttrain-rmse:0.32355\ttest-rmse:0.37184\n",
            "[67]\ttrain-rmse:0.32293\ttest-rmse:0.37151\n",
            "[68]\ttrain-rmse:0.32223\ttest-rmse:0.37140\n",
            "[69]\ttrain-rmse:0.32147\ttest-rmse:0.37119\n",
            "[70]\ttrain-rmse:0.32074\ttest-rmse:0.37099\n",
            "[71]\ttrain-rmse:0.32000\ttest-rmse:0.37094\n",
            "[72]\ttrain-rmse:0.31945\ttest-rmse:0.37084\n",
            "[73]\ttrain-rmse:0.31875\ttest-rmse:0.37066\n",
            "[74]\ttrain-rmse:0.31800\ttest-rmse:0.37054\n",
            "[75]\ttrain-rmse:0.31726\ttest-rmse:0.37036\n",
            "[76]\ttrain-rmse:0.31652\ttest-rmse:0.37023\n",
            "[77]\ttrain-rmse:0.31585\ttest-rmse:0.37001\n",
            "[78]\ttrain-rmse:0.31520\ttest-rmse:0.36986\n",
            "[79]\ttrain-rmse:0.31474\ttest-rmse:0.36979\n",
            "[80]\ttrain-rmse:0.31405\ttest-rmse:0.36957\n",
            "[81]\ttrain-rmse:0.31335\ttest-rmse:0.36941\n",
            "[82]\ttrain-rmse:0.31267\ttest-rmse:0.36931\n",
            "[83]\ttrain-rmse:0.31199\ttest-rmse:0.36904\n",
            "[84]\ttrain-rmse:0.31135\ttest-rmse:0.36878\n",
            "[85]\ttrain-rmse:0.31068\ttest-rmse:0.36854\n",
            "[86]\ttrain-rmse:0.31002\ttest-rmse:0.36849\n",
            "[87]\ttrain-rmse:0.30933\ttest-rmse:0.36824\n",
            "[88]\ttrain-rmse:0.30879\ttest-rmse:0.36808\n",
            "[89]\ttrain-rmse:0.30817\ttest-rmse:0.36793\n",
            "[90]\ttrain-rmse:0.30772\ttest-rmse:0.36776\n",
            "[91]\ttrain-rmse:0.30719\ttest-rmse:0.36764\n",
            "[92]\ttrain-rmse:0.30655\ttest-rmse:0.36754\n",
            "[93]\ttrain-rmse:0.30588\ttest-rmse:0.36732\n",
            "[94]\ttrain-rmse:0.30528\ttest-rmse:0.36729\n",
            "[95]\ttrain-rmse:0.30461\ttest-rmse:0.36707\n",
            "[96]\ttrain-rmse:0.30414\ttest-rmse:0.36697\n",
            "[97]\ttrain-rmse:0.30359\ttest-rmse:0.36687\n",
            "[98]\ttrain-rmse:0.30312\ttest-rmse:0.36676\n",
            "[99]\ttrain-rmse:0.30257\ttest-rmse:0.36674\n",
            "\n",
            "Final Evaluation Metrics:\n",
            "Mean Absolute Error (MAE): 0.2679\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import xgboost as xgb\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "\n",
        "# Convert to DMatrix format for XGBoost\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "\n",
        "# Set parameters for XGBoost regression\n",
        "params = {\n",
        "    'objective': 'reg:squarederror',\n",
        "    'max_depth': 5,\n",
        "    'eta': 0.1,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8\n",
        "}\n",
        "\n",
        "# Train the model with early stopping\n",
        "xgb_model = xgb.train(params, dtrain, num_boost_round=100,\n",
        "                      evals=[(dtrain, 'train'), (dtest, 'test')],\n",
        "                      early_stopping_rounds=10, verbose_eval=True)\n",
        "\n",
        "# Use the trained model for predictions\n",
        "y_pred = xgb_model.predict(dtest)\n",
        "\n",
        "# Calculate Mean Absolute Error\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(\"\\nFinal Evaluation Metrics:\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "106e6947",
      "metadata": {
        "id": "106e6947"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('trained_models/xgboost_model.pkl','wb') as f:\n",
        "  pickle.dump(xgb_model,f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec2cdd36",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec2cdd36",
        "outputId": "81ad70c1-66d3-49af-ca67-148eeb010fa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word2Vec model trained and saved to 'word2vec_model.model'\n"
          ]
        }
      ],
      "source": [
        "# Save the trained model to a file\n",
        "w2v_model.save(\"trained_models/word2vec_model.model\")\n",
        "print(\"Word2Vec model trained and saved to 'word2vec_model.model'\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
